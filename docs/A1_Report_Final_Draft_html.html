<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.24">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>quarto-input7300503f73d78570 – Avalanche Risk Prediction</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dc55a5b9e770e841cd82e46aadbfb9b0.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-3ee09d218e5cb07634f343b39aada8de.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet">

<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>


  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Avalanche Risk Prediction</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./A1_Report_Final_Draft_html.html" aria-current="page"> 
<span class="menu-text">Paper</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./LLMs_Statement.html"> 
<span class="menu-text">AI Statement</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#abstract" id="toc-abstract" class="nav-link active" data-scroll-target="#abstract">Abstract</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#data-methods" id="toc-data-methods" class="nav-link" data-scroll-target="#data-methods">Data &amp; Methods</a>
  <ul class="collapse">
  <li><a href="#data" id="toc-data" class="nav-link" data-scroll-target="#data">Data</a></li>
  <li><a href="#methods-data-preparation-cleaning-and-pre-processing" id="toc-methods-data-preparation-cleaning-and-pre-processing" class="nav-link" data-scroll-target="#methods-data-preparation-cleaning-and-pre-processing">Methods: Data Preparation, Cleaning, and Pre-processing</a></li>
  <li><a href="#methods-neural-ordinal-forecasting-model" id="toc-methods-neural-ordinal-forecasting-model" class="nav-link" data-scroll-target="#methods-neural-ordinal-forecasting-model">Methods: Neural ordinal forecasting model</a></li>
  </ul></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">Results</a>
  <ul class="collapse">
  <li><a href="#class-balance-train-vs-test" id="toc-class-balance-train-vs-test" class="nav-link" data-scroll-target="#class-balance-train-vs-test">Class Balance: Train vs Test</a></li>
  <li><a href="#test-performance-model-vs-baselines" id="toc-test-performance-model-vs-baselines" class="nav-link" data-scroll-target="#test-performance-model-vs-baselines">Test Performance (Model vs Baselines)</a></li>
  <li><a href="#confusion-matrix-and-per-class-report" id="toc-confusion-matrix-and-per-class-report" class="nav-link" data-scroll-target="#confusion-matrix-and-per-class-report">Confusion Matrix and Per-Class Report</a></li>
  <li><a href="#effect-of-threshold-calibration" id="toc-effect-of-threshold-calibration" class="nav-link" data-scroll-target="#effect-of-threshold-calibration">Effect of Threshold Calibration</a></li>
  <li><a href="#error-shape" id="toc-error-shape" class="nav-link" data-scroll-target="#error-shape">Error Shape</a></li>
  </ul></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">Discussion</a>
  <ul class="collapse">
  <li><a href="#metrics-and-diagnostics" id="toc-metrics-and-diagnostics" class="nav-link" data-scroll-target="#metrics-and-diagnostics">Metrics and diagnostics</a></li>
  <li><a href="#factors-underpinning-persistence-performance" id="toc-factors-underpinning-persistence-performance" class="nav-link" data-scroll-target="#factors-underpinning-persistence-performance">Factors underpinning Persistence performance</a></li>
  <li><a href="#operational-interpretation" id="toc-operational-interpretation" class="nav-link" data-scroll-target="#operational-interpretation">Operational interpretation</a></li>
  <li><a href="#limitations" id="toc-limitations" class="nav-link" data-scroll-target="#limitations">Limitations</a></li>
  <li><a href="#possible-future-improvements" id="toc-possible-future-improvements" class="nav-link" data-scroll-target="#possible-future-improvements">Possible future improvements</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#statement-on-the-use-of-ai-llms" id="toc-statement-on-the-use-of-ai-llms" class="nav-link" data-scroll-target="#statement-on-the-use-of-ai-llms">Statement on the use of AI (LLMs)</a>
  <ul class="collapse">
  <li><a href="#ai-implementation-and-utilisation" id="toc-ai-implementation-and-utilisation" class="nav-link" data-scroll-target="#ai-implementation-and-utilisation">AI Implementation and utilisation</a></li>
  <li><a href="#verification-and-academic-integrity" id="toc-verification-and-academic-integrity" class="nav-link" data-scroll-target="#verification-and-academic-integrity">Verification and academic integrity</a></li>
  <li><a href="#representative-prompts" id="toc-representative-prompts" class="nav-link" data-scroll-target="#representative-prompts">Representative prompts</a></li>
  <li><a href="#limits-of-the-ais-role" id="toc-limits-of-the-ais-role" class="nav-link" data-scroll-target="#limits-of-the-ais-role">Limits of the AI�s role</a></li>
  </ul></li>
  <li><a href="#benefits" id="toc-benefits" class="nav-link" data-scroll-target="#benefits">Benefits</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  <li><a href="#appendix" id="toc-appendix" class="nav-link" data-scroll-target="#appendix">Appendix</a>
  <ul class="collapse">
  <li><a href="#data-figures" id="toc-data-figures" class="nav-link" data-scroll-target="#data-figures">Data Figures</a></li>
  <li><a href="#model-results-figures" id="toc-model-results-figures" class="nav-link" data-scroll-target="#model-results-figures">Model / Results Figures</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<p>Forecast avalanche hazard (FAH) is reported on an ordered five-level scale, making the correct ordering of predictions as important as the exact class assignment. We build a modelling-ready dataset from operational observations in Scotland and cast next-day FAH as an ordinal forecasting problem. Data preparation standardises identifiers, audits and repairs missingness, applies physically sensible bounds, encodes circular variables with sine-cosine pairs, and adds seasonal day-of-year features. We split chronologically (80/20) with an embargo to avoid look-ahead.</p>
<p>For modelling, we turn each area�s history into 10-day windows of dynamic features, fuse static site attributes, and train an LSTM with a CORN ordinal head that predicts <span class="math inline">\(K - 1\)</span> exceedance probabilities. Class imbalance is handled by oversampling rare classes in minibatches and class-balanced per-threshold weights in the loss. We then tune monotone thresholds on the most recent validation fold to convert probabilities into labels.</p>
<p>Validation uses forward-chaining time folds; evaluation on a held-out test window reports Accuracy, Macro-F1, MAE, and Quadratic Weighted Kappa (QWK). Compared with three simple baselines (global majority, per-area majority, and persistence), the LSTM-CORN model improves ordinal-aware agreement (QWK) and reduces absolute error (MAE), with most mistakes within one level of the truth. Limitations include scarcity of High hazard days and potential sensitivity to the temporal split, but the approach is reproducible and operationally realistic, and it provides a clear path to calibration and extension.</p>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>According to the Conceptual Model of Avalanche Hazard (Statham et al., 2018), the hazard level is determined by combining two ordinal variables-likelihood of avalanche occurrence and destructive size-into a single danger rating. This motivates treating FAH as an ordinal rather than a nominal target.</p>
<p>Data preparation (in R) standardises identifiers, audits and repairs missing values, applies physical plausibility checks, encodes circular angles as sine/cosine, and adds day-of-year seasonality. Model matrices are exported with an ordered target, and a chronological <span class="math inline">\(80/20\)</span> split prevents look-ahead.</p>
<p>Methodologically, we use a sequence model to reflect that hazard depends on recent conditions. We frame each area-day as a one-step-ahead forecast and feed the model a fixed 10-day look-back of daily predictors together with static site attributes. This mirrors the standard time-series set-up in which inputs comprise a recent window of observations plus static metadata (Lim and Zohren, 2021; Eq. 2.1). We implement the encoder with an LSTM over the 10-day window and concatenate the static features before the output layer.</p>
</section>
<section id="data-methods" class="level2">
<h2 class="anchored" data-anchor-id="data-methods">Data &amp; Methods</h2>
<section id="data" class="level3">
<h3 class="anchored" data-anchor-id="data">Data</h3>
<p>We analysed a 2009-2025 archive of daily avalanche forecasts from the Scottish Avalanche Information Service across six forecasting regions. The prediction target is the forecast avalanche hazard (FAH) for the following day, encoded as an <em>ordered</em> categorical variable with levels:</p>
<p><em>Low &lt; Moderate &lt; Considerable - &lt; Considerable + &lt; High</em></p>
<p>Predictors comprise:<br>
1. <strong>Site and topography</strong> - OS grid identifier, location name, longitude, latitude, altitude, incline.<br>
2. <strong>Contemporaneous meteorology</strong> near the forecast location - summit air temperature, summit wind speed and direction, lower-level winds, cloud, and insolation.<br>
3. <strong>Snowpack observations</strong> derived from field tests - snow temperature, maximum temperature and hardness gradients, foot and ski penetration indices, crystal type, wetness, and a derived stability index.</p>
<p>The observed hazard (OAH) was removed from the dataset to prevent leakage.</p>
<div style="page-break-after: always;"></div>
</section>
<section id="methods-data-preparation-cleaning-and-pre-processing" class="level3">
<h3 class="anchored" data-anchor-id="methods-data-preparation-cleaning-and-pre-processing">Methods: Data Preparation, Cleaning, and Pre-processing</h3>
<section id="type-standardisation-and-initial-feature-engineering" class="level4">
<h4 class="anchored" data-anchor-id="type-standardisation-and-initial-feature-engineering">Type standardisation and initial feature engineering</h4>
<p>We parsed timestamps into date components (year, month, DOY, season), converted IDs to appropriate types (e.g., <code>Area</code> as a factor), and stored FAH as an ordered factor (<code>FAH_ord</code>) to preserve ordinal structure for modelling and evaluation.</p>
</section>
<section id="spatial-consistency-checks" class="level4">
<h4 class="anchored" data-anchor-id="spatial-consistency-checks">Spatial consistency checks</h4>
<p>OS grids represents areas rather than single points, so longitude, latitude, and altitude vary within them. Therefore, we did not impute altitude from the grid ID: since each grid covers heterogeneous terrain, we instead queried elevation using precise coordinates.</p>
</section>
<section id="record-keys-duplicates-and-consolidation" class="level4">
<h4 class="anchored" data-anchor-id="record-keys-duplicates-and-consolidation">Record keys, duplicates, and consolidation</h4>
<p>We treated (Date, OSgrid, Area) as the record key. For any key with multiple rows, we counted-column by column-how many distinct non-missing values appeared.</p>
<ul>
<li>If the duplicates differed only by missing values, we collapsed them to a single row, taking the first available non-missing value in each column.</li>
<li>If any column showed truly conflicting observations (more than one distinct non-missing value), we kept all rows for that key and flagged the group as conflicted.</li>
</ul>
<p>This approach preserves genuine differences, avoids inventing data, and leaves a clear audit trail wherever sources disagree.</p>
</section>
<section id="missingness-audit-and-design-of-indicators" class="level4">
<h4 class="anchored" data-anchor-id="missingness-audit-and-design-of-indicators">Missingness audit and design of indicators</h4>
<p>We measured missingness per variable and, where the absence was informative, created 0/1 ‘was-missing’ flags before any outlier recoding. These were made for: AV.cat, Ski.pen, Crystals, Wetness, Snow.Index, and summit weather fields (Wind Dir/Speed, Air Temp). Creating these early preserves the original data structure. Fields like Max.Temp.Grad, Max.Hardness.Grad are blank when no snow pit is done. So, we imputed those numeric blanks downstream rather than adding indicators.</p>
<p><strong>Snow.Index check:</strong> Many values are exactly zero. We tested whether zeros signified ‘no test’ and found they did not, i.e., rows with zeros showed no elevated missingness in pit variables. We therefore kept zeros as valid measurements and treated only NAs as missing.</p>
</section>
<section id="physically-defensible-plausibility-filters" class="level4">
<h4 class="anchored" data-anchor-id="physically-defensible-plausibility-filters">Physically defensible plausibility filters</h4>
<p>We applied conservative plausibility checks and recoded violations to <code>NA</code> for later imputation. The limits reflect basic physical and local constraints (e.g., angles in <span class="math inline">\(0{-}360^\circ\)</span>, non-negative depths).</p>
<ul>
<li>Directional variables (Aspect, Wind.Dir, Summit.Wind.Dir): values outside <span class="math inline">\([0^\circ, 360^\circ]\)</span> set to <code>NA</code>.<br>
</li>
<li>Snow temperature (<span class="math inline">\(^\circ\)</span>C): values <span class="math inline">\(&gt; 5\)</span> set to NA (snow cannot persist above <span class="math inline">\(\sim 0^\circ\)</span>C; a small buffer accommodates sensor and entry noise).<br>
</li>
<li>Insolation (index): values outside <span class="math inline">\(0{-}20\)</span> set to NA.<br>
</li>
<li>Incline (<span class="math inline">\(^\circ\)</span>): values <span class="math inline">\(&lt;0\)</span> or <span class="math inline">\(&gt;90\)</span> set to NA.<br>
</li>
<li>Foot penetration (cm): values <span class="math inline">\(&lt;0\)</span> or <span class="math inline">\(&gt;100\)</span> set to NA.<br>
</li>
<li>Total snow depth (cm): values <span class="math inline">\(&lt;0\)</span> or <span class="math inline">\(&gt;500\)</span> set to NA (regional plausibility).<br>
</li>
<li>Maximum temperature gradient (<span class="math inline">\(^\circ\)</span>C/10 cm): values <span class="math inline">\(&gt; 10\)</span> set to NA.<br>
</li>
<li>Altitude (m): values <span class="math inline">\(&lt;0\)</span> or <span class="math inline">\(&gt;1400\)</span> set to NA (Scotland�s highest peak <span class="math inline">\(\approx 1345\)</span> m).</li>
</ul>
</section>
<section id="altitude-repair-via-coordinate-based-elevation-lookup" class="level4">
<h4 class="anchored" data-anchor-id="altitude-repair-via-coordinate-based-elevation-lookup">Altitude repair via coordinate-based elevation lookup</h4>
<p>For missing altitudes, we queried an open elevation service at rounded coordinates and filled <code>Alt</code> where values were returned. One query returned <span class="math inline">\(0\)</span> m (a sea-loch), indicating a geolocation error. We replaced it with the area mean (Creag Meagaidh) and re-queried. Results are cached locally for deterministic compilation and used if the service is unavailable.</p>
</section>
<section id="circular-encodings-for-directional-variables" class="level4">
<h4 class="anchored" data-anchor-id="circular-encodings-for-directional-variables">Circular encodings for directional variables</h4>
<p>As angles wrap at <span class="math inline">\(360^\circ\)</span>, treating them as numeric creates an artificial jump between <span class="math inline">\(359^\circ\)</span> and <span class="math inline">\(0^\circ\)</span>. We replaced each directional variable (<code>Wind.Dir</code>, <code>Summit.Wind.Dir</code>, <code>Aspect</code>) with the sine and cosine of the angle (radians). This keeps <span class="math inline">\(0^\circ\)</span> and <span class="math inline">\(360^\circ\)</span> close in feature space, and removes the wrap-around discontinuity. Missing angles remained missing in both components and were imputed later.</p>
</section>
<section id="time-aware-splitting-and-leakage-control" class="level4">
<h4 class="anchored" data-anchor-id="time-aware-splitting-and-leakage-control">Time-aware splitting and leakage control</h4>
<p>We split the data chronologically into <span class="math inline">\(80\%\)</span> training and <span class="math inline">\(20\%\)</span> test (non-overlapping), dropping rows with missing <code>Date</code> or target (<code>FAH_ord</code>) before the split. We checked class balance in each split. The High level is very rare and absent in the test window, so performance on it cannot be evaluated. All preprocessing (imputation, scaling, encoding) was fit on the training set and applied unchanged to the test set to avoid leakage.</p>
</section>
<section id="pre-processing-pipeline-for-modelling-recipes" class="level4">
<h4 class="anchored" data-anchor-id="pre-processing-pipeline-for-modelling-recipes">Pre-processing pipeline for modelling (recipes)</h4>
<p>A single, train-fitted <code>recipes</code> pipeline was implemented with the following stages:</p>
<ol type="1">
<li><strong>Column exclusion:</strong> Dropped identifiers and free text, raw time stamps, and raw angles: <code>OSgrid</code>, <code>Location</code>, <code>Date</code>, <code>DateTime</code>, raw <code>Wind.Dir</code>, raw <code>Summit.Wind.Dir</code>, and raw <code>Aspect</code>. The raw target FAH was excluded in favour of <code>FAH_ord</code>.<br>
</li>
<li><strong>Rare-level consolidation:</strong> Collapsed very rare categorical levels to <code>"other"</code> using <span class="math inline">\(\texttt{threshold} = 0.005\)</span> to avoid sparse dummies.<br>
</li>
<li><strong>Imputation:</strong> Categorical variables were imputed by mode; numerical variables by bagged-tree imputation (bootstrap ensembles estimated on the training data), which captures non-linearities and interactions in mixed meteorological and snowpack features more effectively than mean or KNN imputation.<br>
</li>
<li><strong>Encoding:</strong> One-hot encoding of categorical predictors (including <code>Area</code>).<br>
</li>
<li><strong>Variance filtering:</strong> Removal of zero-variance and near-zero-variance predictors.<br>
</li>
<li><strong>Scaling:</strong> Standardisation of numerical predictors, excluding the 0/1 informative-missing indicators (and area dummies).<br>
</li>
<li><strong>Seasonality:</strong> Replacement of discrete season dummies with smooth cyclical features <span class="math inline">\(doy\_sin\)</span> and <span class="math inline">\(doy\_cos\)</span> (constructed from day-of-year with leap years handled); season binaries were removed to reduce collinearity.<br>
</li>
<li><strong>Target mapping:</strong> The ordered response was mapped once to integers <span class="math inline">\(0{-}4\)</span> to provide a single source of truth for neural-network models.</li>
</ol>
</section>
<section id="reproducibility-diagnostics-and-assumptions" class="level4">
<h4 class="anchored" data-anchor-id="reproducibility-diagnostics-and-assumptions">Reproducibility, diagnostics, and assumptions</h4>
<p>We fixed random seeds and kept all data-prep and modelling steps in a single scripted pipeline. After baking the recipe, there were no remaining missing values in either split. We re-checked the composite key (<code>Date</code>, <code>OSgrid</code>, <code>Area</code>) after duplicate handling, and we spot-checked distributions of imputed variables to make sure they looked reasonable. Elevation queries are cached locally, so reruns do not depend on the external service.</p>
<p>Our working assumptions were:<br>
(i) the value ranges we used to flag implausible measurements reflect Scottish conditions;<br>
(ii) <code>Snow.Index == 0</code> is a <strong>valid zero</strong> (stable conditions), not a stand-in for “no test”; and<br>
(iii) the “informative-missing” indicators genuinely capture absence at the time of collection rather than artefacts created later in cleaning.</p>
</section>
<section id="limitations-and-sensitivity-considerations" class="level4">
<h4 class="anchored" data-anchor-id="limitations-and-sensitivity-considerations">Limitations and sensitivity considerations</h4>
<p>The High hazard class is rare (and absent in our test window) so standard accuracy alone can be misleading. We therefore report macro-averaged scores and discuss calibration in the results, but performance on the very rarest conditions remains uncertain. The plausibility cut-offs (e.g., the threshold for snow temperature) are conservative choices, not unique truths; reasonable alternatives could be used, and results may shift slightly.</p>
<p>Finally, because we split by time, outcomes can vary with the split date (e.g., if conditions change from one season to the next). This is typical in operational forecasting, so sensitivity checks (e.g., alternate split points or small variations in thresholds and look-back length) would be a natural extension.</p>
</section>
</section>
<section id="methods-neural-ordinal-forecasting-model" class="level3">
<h3 class="anchored" data-anchor-id="methods-neural-ordinal-forecasting-model">Methods: Neural ordinal forecasting model</h3>
<p>The neural network implementation was done in python, using PyTorch. Given the temporal component of the data, a recurrent network architecture was used over a standard feed-forward setup, which is incapable of “remembering” anything about past observations. Specifically, a Long Short Term Memory (LSTM) design was employed, which is less susceptible to vanishing and exploding gradients.</p>
<section id="data-interface-and-temporal-windows" class="level4">
<h4 class="anchored" data-anchor-id="data-interface-and-temporal-windows">Data interface and temporal windows</h4>
<p>The data were split into sequences for the recurrent architecture. Static features (longitude, latitude, altitude, incline, area dummies) were held constant across sequences, while dynamic features comprised all remaining numeric variables and the missingness indicators. A new feature of the previous day�s hazard rating, <code>FAH_prev</code>, was created and added to the dynamic set.</p>
<p>Area-wise sliding windows with look-back <span class="math inline">\(L = 10\)</span> days and horizon <span class="math inline">\(H = 0\)</span> were built with an embargo (Lim and Zohren, 2021; Eq. 2.1). The train/test split matches the R setup (<span class="math inline">\(80\%\)</span> earliest dates for training, remaining <span class="math inline">\(20\%\)</span> for testing), and windows were constructed after concatenation and filtered by the target date to prevent test leakage.</p>
</section>
<section id="architecture-and-loss-corn-lstm" class="level4">
<h4 class="anchored" data-anchor-id="architecture-and-loss-corn-lstm">Architecture and loss (CORN-LSTM)</h4>
<p>The LSTM�s final hidden state after being trained is passed through a small MLP head. Instead of using softmax over the class predictions and Cross-Entropy (CE) error, we used a technique called Cumulative Ordinal Regression for Neural Networks (CORN). The CORN layer follows the MLP head, and produces <span class="math inline">\(K - 1\)</span> logits that are then used to determine progress through a set of ordered binaries on whether a prediction is of a certain class, <span class="math inline">\(\Pr(y &gt; 0)\)</span>, <span class="math inline">\(\Pr(y &gt; 1)\)</span>, <span class="math inline">\(\ldots\)</span>, <span class="math inline">\(\Pr(y &gt; K - 2)\)</span>. Because these events become harder as <span class="math inline">\(k\)</span> grows, their probabilities naturally decrease with <span class="math inline">\(k\)</span> (Cao, Mirjalili and Raschka, 2020).</p>
<p>During training, We compute CORN targets from the true class and minimise Binary Cross-Entropy (BCE) on the <span class="math inline">\(K - 1\)</span> logits. At inference, we threshold the <span class="math inline">\(K - 1\)</span> probabilities, count how many exceed their thresholds, and that count is the predicted FAH level. This approach is superior to CE error, which treats classes as nominal, and does not distinguish between degrees of misclassification.</p>
</section>
<section id="class-imbalance-handling" class="level4">
<h4 class="anchored" data-anchor-id="class-imbalance-handling">Class imbalance handling</h4>
<p>We addressed class imbalance between high and low hazard level predictions using two techniques: (1) oversampling in the training loader (<code>WeightedRandomSampler</code>) to increase rare FAH frequencies during optimisation, and (2) Class-balanced CORN loss, which weights each class by its effective number of samples <span class="math inline">\((1 - \beta)/(1 - \beta^{n_c})\)</span>. For each threshold <span class="math inline">\(k\)</span>, we compute a positive weight (<span class="math inline">\(\beta = 0.999\)</span>) and apply it in the BCE term so rare exceedance events <span class="math inline">\((y &gt; k)\)</span> contribute proportionally more without duplicating data (Cui et al., 2019). This has the effect of upweighting rare events, making them mater more in the BCE loss.</p>
</section>
<section id="validation-protocol-hyperparameter-search-and-early-stopping" class="level4">
<h4 class="anchored" data-anchor-id="validation-protocol-hyperparameter-search-and-early-stopping">Validation protocol, hyperparameter search, and early stopping</h4>
<p>In order to conduct hyperparameter tuning for the chosen model architecture, an appropriate validation framework was implemented. In order to maximise data for training and testing, cross validation was employed. We created forward-chaining time folds (<span class="math inline">\(K=5\)</span>) with an embargo of length $ L $ before each validation slice to avoid look-ahead leakage. For a fold k, the validation set is a contiguous block of unique target dates, and the training is all earlier sequences, except for the embargo before the validation block to prevent leakage. This means that there is an expanding window as we move forward in time, so the training includes more history, and there is no random shuffling, which would be inappropriate in this context.</p>
<p>We tuned hyperparameters with <strong>Optuna</strong> over:</p>
<ul>
<li>hidden size <span class="math inline">\(\{32, 48, 64\}\)</span>,</li>
<li>number of LSTM layers <span class="math inline">\(\{1, 2\}\)</span>,</li>
<li>head dropout <span class="math inline">\([0.1, 0.5]\)</span>,</li>
<li>RNN dropout (only if <span class="math inline">\(\geq 2\)</span> layers),</li>
<li>learning rate <span class="math inline">\([10^{-4}, 3 \times 10^{-3}]\)</span>,</li>
<li>weight decay <span class="math inline">\([10^{-6}, 10^{-3}]\)</span>,</li>
<li>batch size <span class="math inline">\(\{128, 256, 512\}\)</span>.</li>
</ul>
<p>The objective was to maximise the mean Quadratic Weighted Kappa (QWK), which rewards getting close on an ordinal scale across folds. Training used Adam, gradient-norm clipping (1.0), and early stopping on validation QWK.</p>
</section>
<section id="threshold-calibration-monotone-tau" class="level4">
<h4 class="anchored" data-anchor-id="threshold-calibration-monotone-tau">Threshold calibration (monotone <span class="math inline">\(\tau\)</span>)</h4>
<p>After selection, the model was refit on all training windows and thresholds were calibrated on the most recent validation fold, then fixed for test, since the last validation fold should be more similar to the test distribution. These thresholds are used to turn the CORN outputs of <span class="math inline">\(K - 1\)</span> probabilities into labels. They were tuned on the latest validation fold using a simple grid over <span class="math inline">\(0.3\)</span>-<span class="math inline">\(0.7\)</span>, selecting the vector that maximises QWK. they are monotone non-increasing, <span class="math inline">\(\tau_1 \ge \tau_2 \ge \cdots \ge \tau_{K-1}\)</span> , because <span class="math inline">\(\Pr(y &gt; k)\)</span> decreases with <span class="math inline">\(k\)</span>; later thresholds should never be easier to exceed than earlier ones.</p>
<p>The tuned vector used for test was:</p>
<p><span class="math display">\[ \tau = [0.52, \; 0.50, \; 0.50, \; 0.48].
\]</span></p>
</section>
<section id="final-refit-and-test-evaluation" class="level4">
<h4 class="anchored" data-anchor-id="final-refit-and-test-evaluation">Final refit and test evaluation</h4>
<p>We refit the model on all training windows, keeping a small, chronological <span class="math inline">\(90/10\)</span> tail for early stopping. We then evaluate once on the held-out test windows using the fixed <span class="math inline">\(\tau\)</span> vector above. Metrics reported are Accuracy, Macro-F1, MAE, and QWK, and include a confusion matrix and a per-class report in the Results.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>488</code></pre>
</div>
</div>
</section>
<section id="baselines" class="level4">
<h4 class="anchored" data-anchor-id="baselines">Baselines</h4>
<p>For context, we implemented three simple non-parametric reference models as baselines (all fitted only on training labels).</p>
<ol type="i">
<li>a <strong>global majority</strong> classifier that predicts the most frequent FAH level in the training labels,<br>
</li>
<li>a <strong>per-area majority</strong> classifier that uses the most frequent FAH level within each area (assigned to that area in test), and<br>
</li>
<li>a <strong>persistence</strong> rule <span class="math inline">\(\hat{y}_t = y_{t-1}\)</span> within area, with a majority fallback for an area�s first test day.</li>
</ol>
<p>We report the same metrics used for the neural model (Accuracy, Macro-F1, MAE, QWK) to enable direct comparison.</p>
<div style="page-break-after: always;"></div>
</section>
</section>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>We evaluate the tuned LSTM-CORN on the held-out test window and compare it with three simple baselines.<br>
All settings were fixed before touching the test set. We report Accuracy, Macro-F1, MAE, and Quadratic Weighted Kappa (QWK);<br>
a confusion matrix and per-class summary show where errors occur.</p>
<pre><code></code></pre>
<section id="class-balance-train-vs-test" class="level3">
<h3 class="anchored" data-anchor-id="class-balance-train-vs-test">Class Balance: Train vs Test</h3>
<p>Higher hazard levels are rare, and the distribution also shifts over time. In our split the High level does not occur in the test window, which matters for both training and evaluation. The table below shows the proportion of each FAH level within each split (percents within Train/Test):</p>
<style type="text/css">
#T_83b36 th {
  text-align: right;
}
#T_83b36 td {
  text-align: right;
}
#T_83b36 caption {
  caption-side: top;
  font-weight: 600;
}
#T_83b36_row0_col0, #T_83b36_row1_col0, #T_83b36_row2_col0, #T_83b36_row3_col0, #T_83b36_row4_col0 {
  text-align: left;
  white-space: nowrap;
}
</style>
<table id="T_83b36" class="table table-sm table-striped">
<caption>
FAH class balance by split.
</caption>
<thead>
<tr>
<th id="T_83b36_level0_col0" class="col_heading level0 col0">
</th>
<th id="T_83b36_level0_col1" class="col_heading level0 col1" colspan="2">
count
</th>
<th id="T_83b36_level0_col3" class="col_heading level0 col3" colspan="2">
percent
</th>
</tr>
<tr>
<th id="T_83b36_level1_col0" class="col_heading level1 col0">
FAH level
</th>
<th id="T_83b36_level1_col1" class="col_heading level1 col1">
Test
</th>
<th id="T_83b36_level1_col2" class="col_heading level1 col2">
Train
</th>
<th id="T_83b36_level1_col3" class="col_heading level1 col3">
Test
</th>
<th id="T_83b36_level1_col4" class="col_heading level1 col4">
Train
</th>
</tr>
</thead>
<tbody>
<tr>
<td id="T_83b36_row0_col0" class="data row0 col0">
0
</td>
<td id="T_83b36_row0_col1" class="data row0 col1">
1,209
</td>
<td id="T_83b36_row0_col2" class="data row0 col2">
2,222
</td>
<td id="T_83b36_row0_col3" class="data row0 col3">
57.3%
</td>
<td id="T_83b36_row0_col4" class="data row0 col4">
26.3%
</td>
</tr>
<tr>
<td id="T_83b36_row1_col0" class="data row1 col0">
1
</td>
<td id="T_83b36_row1_col1" class="data row1 col1">
644
</td>
<td id="T_83b36_row1_col2" class="data row1 col2">
2,593
</td>
<td id="T_83b36_row1_col3" class="data row1 col3">
30.5%
</td>
<td id="T_83b36_row1_col4" class="data row1 col4">
30.7%
</td>
</tr>
<tr>
<td id="T_83b36_row2_col0" class="data row2 col0">
2
</td>
<td id="T_83b36_row2_col1" class="data row2 col1">
171
</td>
<td id="T_83b36_row2_col2" class="data row2 col2">
2,327
</td>
<td id="T_83b36_row2_col3" class="data row2 col3">
8.1%
</td>
<td id="T_83b36_row2_col4" class="data row2 col4">
27.5%
</td>
</tr>
<tr>
<td id="T_83b36_row3_col0" class="data row3 col0">
3
</td>
<td id="T_83b36_row3_col1" class="data row3 col1">
84
</td>
<td id="T_83b36_row3_col2" class="data row3 col2">
849
</td>
<td id="T_83b36_row3_col3" class="data row3 col3">
4.0%
</td>
<td id="T_83b36_row3_col4" class="data row3 col4">
10.0%
</td>
</tr>
<tr>
<td id="T_83b36_row4_col0" class="data row4 col0">
4
</td>
<td id="T_83b36_row4_col1" class="data row4 col1">
1
</td>
<td id="T_83b36_row4_col2" class="data row4 col2">
458
</td>
<td id="T_83b36_row4_col3" class="data row4 col3">
0.0%
</td>
<td id="T_83b36_row4_col4" class="data row4 col4">
5.4%
</td>
</tr>
</tbody>
</table>
<p>The training set shows a relatively balanced distribution across Levels 0-2 (approximately <span class="math inline">\(26\%\)</span>-<span class="math inline">\(31\%\)</span> each), with Level 3 at around <span class="math inline">\(10\%\)</span> and Level 4 at <span class="math inline">\(5\%\)</span> . The test set, however, is heavily skewed: Level 0 dominates ( <span class="math inline">\(\approx 57\%\)</span>), followed by Level 1 (<span class="math inline">\(31\%\)</span> ), Level 2 (<span class="math inline">\(8\%\)</span>), Level 3 (<span class="math inline">\(4\%\)</span>), and Level 4 is virtually absent ( <span class="math inline">\(\sim 0\%\)</span>).</p>
<p>This shift has important implications. A naive model that predicts Level 0 can achieve high Accuracy despite poor overall performance. Macro-F1 and QWK are therefore more informative, as they weight classes evenly and penalise larger ordinal errors. To address the imbalance, the training procedure uses oversampling and a class-balanced CORN loss, while threshold calibration on the final fold helps adapt the decision rule to the test distribution.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="A1_Report_Final_Draft_html_files/figure-html/unnamed-chunk-35-1.png" class="img-fluid figure-img" width="480"></p>
<figcaption>Bar Plot illustrating FAH class balance by split.</figcaption>
</figure>
</div>
</div>
</div>
<div style="page-break-after: always;"></div>
</section>
<section id="test-performance-model-vs-baselines" class="level3">
<h3 class="anchored" data-anchor-id="test-performance-model-vs-baselines">Test Performance (Model vs Baselines)</h3>
<p>Below we compare the tuned LSTM-CORN model with three simple baselines. We evaluate performance using four metrics: <strong>Accuracy</strong>, <strong>Macro-F1</strong>, <strong>Mean Absolute Error (MAE)</strong>, and <strong>Quadratic Weighted Kappa (QWK)</strong>. Accuracy measures the proportion of exact predictions but can be misleading under class imbalance (e.g., always predicting the majority class). Macro-F1 computes precision and recall per class, takes their harmonic mean, and averages equally across classes. This handles imbalance better but ignores class ordering. MAE uses the ordinal scale directly, averaging absolute differences between true and predicted levels (e.g., a miss of <span class="math inline">\(0 \to 1\)</span> counts as 1, while <span class="math inline">\(0 \to 4\)</span> counts as 4), with a range from <span class="math inline">\(0\)</span> to <span class="math inline">\(K - 1\)</span>. QWK is a chance-corrected agreement measure that penalises larger ordinal gaps using quadratic weights. It ranges from 1 (perfect) to 0 (chance) and can be less than 0 (worse than chance), making it well suited to ordinal targets and useful for validation.</p>
<div id="tbl-metrics-html" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl quarto-uncaptioned" id="tbl-metrics-html-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1
</figcaption>
<div aria-describedby="tbl-metrics-html-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<style type="text/css">
#T_ba152 th {
  text-align: right;
}
#T_ba152 td {
  text-align: right;
}
#T_ba152 caption {
  caption-side: top;
  font-weight: 600;
}
#T_ba152_row0_col0, #T_ba152_row1_col0, #T_ba152_row2_col0, #T_ba152_row3_col0 {
  text-align: left;
  white-space: nowrap;
}
</style>
<table id="T_ba152" class="table table-sm table-striped">
<caption>
Performance comparison between LSTM-CORN and baseline models.
</caption>
<thead>
<tr>
<th id="T_ba152_level0_col0" class="col_heading level0 col0">
Model
</th>
<th id="T_ba152_level0_col1" class="col_heading level0 col1">
Accuracy
</th>
<th id="T_ba152_level0_col2" class="col_heading level0 col2">
Macro-F1
</th>
<th id="T_ba152_level0_col3" class="col_heading level0 col3">
MAE
</th>
<th id="T_ba152_level0_col4" class="col_heading level0 col4">
QWK
</th>
</tr>
</thead>
<tbody>
<tr>
<td id="T_ba152_row0_col0" class="data row0 col0">
LSTM-CORN (tuned tau)
</td>
<td id="T_ba152_row0_col1" class="data row0 col1">
0.640
</td>
<td id="T_ba152_row0_col2" class="data row0 col2">
0.299
</td>
<td id="T_ba152_row0_col3" class="data row0 col3">
0.438
</td>
<td id="T_ba152_row0_col4" class="data row0 col4">
0.406
</td>
</tr>
<tr>
<td id="T_ba152_row1_col0" class="data row1 col0">
Majority (global)
</td>
<td id="T_ba152_row1_col1" class="data row1 col1">
0.305
</td>
<td id="T_ba152_row1_col2" class="data row1 col2">
0.094
</td>
<td id="T_ba152_row1_col3" class="data row1 col3">
0.735
</td>
<td id="T_ba152_row1_col4" class="data row1 col4">
0.000
</td>
</tr>
<tr>
<td id="T_ba152_row2_col0" class="data row2 col0">
Majority (per-area)
</td>
<td id="T_ba152_row2_col1" class="data row2 col1">
0.393
</td>
<td id="T_ba152_row2_col2" class="data row2 col2">
0.200
</td>
<td id="T_ba152_row2_col3" class="data row2 col3">
0.755
</td>
<td id="T_ba152_row2_col4" class="data row2 col4">
0.090
</td>
</tr>
<tr>
<td id="T_ba152_row3_col0" class="data row3 col0">
Persistence (y[t-1])
</td>
<td id="T_ba152_row3_col1" class="data row3 col1">
0.719
</td>
<td id="T_ba152_row3_col2" class="data row3 col2">
0.456
</td>
<td id="T_ba152_row3_col3" class="data row3 col3">
0.329
</td>
<td id="T_ba152_row3_col4" class="data row3 col4">
0.659
</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<style type="text/css">
#T_8d8e0 th {
  text-align: right;
}
#T_8d8e0 td {
  text-align: right;
}
#T_8d8e0 caption {
  caption-side: top;
  font-weight: 600;
}
#T_8d8e0_row0_col0, #T_8d8e0_row1_col0, #T_8d8e0_row2_col0, #T_8d8e0_row3_col0 {
  text-align: left;
  white-space: nowrap;
}
</style>
<table id="T_8d8e0" class="table table-sm table-striped">
<caption>
Test-set performance: model vs baselines.
</caption>
<thead>
<tr>
<th id="T_8d8e0_level0_col0" class="col_heading level0 col0">
Model
</th>
<th id="T_8d8e0_level0_col1" class="col_heading level0 col1">
Accuracy
</th>
<th id="T_8d8e0_level0_col2" class="col_heading level0 col2">
Macro-F1
</th>
<th id="T_8d8e0_level0_col3" class="col_heading level0 col3">
MAE
</th>
<th id="T_8d8e0_level0_col4" class="col_heading level0 col4">
QWK
</th>
</tr>
</thead>
<tbody>
<tr>
<td id="T_8d8e0_row0_col0" class="data row0 col0">
LSTM-CORN (tuned tau)
</td>
<td id="T_8d8e0_row0_col1" class="data row0 col1">
0.640
</td>
<td id="T_8d8e0_row0_col2" class="data row0 col2">
0.299
</td>
<td id="T_8d8e0_row0_col3" class="data row0 col3">
0.438
</td>
<td id="T_8d8e0_row0_col4" class="data row0 col4">
0.406
</td>
</tr>
<tr>
<td id="T_8d8e0_row1_col0" class="data row1 col0">
Majority (global)
</td>
<td id="T_8d8e0_row1_col1" class="data row1 col1">
0.305
</td>
<td id="T_8d8e0_row1_col2" class="data row1 col2">
0.094
</td>
<td id="T_8d8e0_row1_col3" class="data row1 col3">
0.735
</td>
<td id="T_8d8e0_row1_col4" class="data row1 col4">
0.000
</td>
</tr>
<tr>
<td id="T_8d8e0_row2_col0" class="data row2 col0">
Majority (per-area)
</td>
<td id="T_8d8e0_row2_col1" class="data row2 col1">
0.393
</td>
<td id="T_8d8e0_row2_col2" class="data row2 col2">
0.200
</td>
<td id="T_8d8e0_row2_col3" class="data row2 col3">
0.755
</td>
<td id="T_8d8e0_row2_col4" class="data row2 col4">
0.090
</td>
</tr>
<tr>
<td id="T_8d8e0_row3_col0" class="data row3 col0">
Persistence (y[t-1])
</td>
<td id="T_8d8e0_row3_col1" class="data row3 col1">
0.719
</td>
<td id="T_8d8e0_row3_col2" class="data row3 col2">
0.456
</td>
<td id="T_8d8e0_row3_col3" class="data row3 col3">
0.329
</td>
<td id="T_8d8e0_row3_col4" class="data row3 col4">
0.659
</td>
</tr>
</tbody>
</table>
<p>On the held-out test window, the persistence rule (predict today as yesterday within area) is the strongest comparator: QWK <span class="math inline">\(\approx 0.659\)</span>, Accuracy <span class="math inline">\(\approx 0.719\)</span>, MAE <span class="math inline">\(\approx 0.329\)</span>, Macro-F1 <span class="math inline">\(\approx 0.456\)</span> The tuned LSTM-CORN improves markedly over the two majority heuristics but does not reach persistence, with QWK <span class="math inline">\(\approx 0.390\)</span>, Accuracy <span class="math inline">\(\approx 0.648\)</span>, MAE <span class="math inline">\(\approx 0.433\)</span>, and Macro-F1 <span class="math inline">\(\approx 0.295\)</span>.<br>
</p>
<p>The majority baselines are near chance in ordinal agreement (global QWK <span class="math inline">\(\approx 0\)</span>; per-area QWK <span class="math inline">\(\approx 0.09\)</span>), confirming that always picking the common class is not competitive.</p>
<p>To read these numbers: <strong>QWK</strong> (Quadratic Weighted Kappa) is our most appropriate headline metric because it respects ordering, penalising large misses more than adjacent ones (higher is better). <strong>MAE</strong> reports the average absolute distance between forecast and truth on the 0-4 scale (lower is better). <strong>Accuracy</strong> is exact-match rate and can look flattering under imbalance, while <strong>Macro-F1</strong> balances precision and recall across classes by giving each class equal weight.</p>
<p>The pattern suggests the test period is highly persistent and skewed toward lower hazard-there are no “High” days-so copying yesterday is often correct and unusually hard to beat. Although the neural model learns meaningful ordinal structure (clear gains over majority rules), it trails persistence on this particular window, likely due to strong day-to-day autocorrelation and a distribution shift between train and test.</p>
<p>Class-wise performance is therefore uneven, with under-prediction at the upper levels and most errors occurring between adjacent categories-which QWK appropriately down-weights. In practice, persistence remains the operational benchmark in stable regimes, while the LSTM-CORN is most promising for anticipating changes in hazard; we examine this further via the confusion matrix and per-class summaries.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="A1_Report_Final_Draft_html_files/figure-html/fig-qwk-3.png" class="img-fluid figure-img" width="576"></p>
<figcaption>QWK of the tuned LSTM-CORN model compared to the three simple baselines.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="confusion-matrix-and-per-class-report" class="level3">
<h3 class="anchored" data-anchor-id="confusion-matrix-and-per-class-report">Confusion Matrix and Per-Class Report</h3>
<p>The matrix shows a clear <strong>ordinal pattern</strong>. Class 0 is predicted well (about <span class="math inline">\(0.90\)</span> on the diagonal), with a small spill into class 1. For class 1, only <span class="math inline">\(\sim 0.39\)</span> stays on the diagonal, and <span class="math inline">\(\sim 0.58\)</span> is pushed down to 0; the model tends to <strong>under-forecast</strong> when conditions are near the 0/1 boundary. Class 2 is mostly confused with undefined (<span class="math inline">\(\approx 0.47\)</span>) and sometimes with 0 (<span class="math inline">\(\approx 0.37\)</span>); only <span class="math inline">\(\sim 0.16\)</span> is correct. Class 3 is rarely predicted directly (<span class="math inline">\(\sim 0.15\)</span> diagonal) and is most often mapped to 1 (<span class="math inline">\(\approx 0.52\)</span>) or 0 (<span class="math inline">\(\approx 0.31\)</span>). There is effectively no reliable signal for class 4 in the test window (support is 1 and it is predicted as a 1), so per-class scores for 4 are unstable and shouldn�t be over-interpreted.</p>
<p>This pattern matches the aggregate metrics reported earlier: overall accuracy and MAE are reasonable, but Macro-F1 and QWK suffer because the model compresses higher hazards toward the centre/lower classes. In other words, most errors are one-step, downward mistakes, good for avoiding extreme over-calls but conservative relative to true highs.</p>
<p>If the operational goal is to catch more 2-3 days (accepting some extra false alarms), you could lower the upper CORN thresholds slightly or use a cost-sensitive tuning target. If the priority is minimising over-warnings, the current calibration is aligned with that objective.</p>
<pre><code>      Class  precision  recall  f1-score  support</code></pre>
<p>0 0 0.699 0.905 0.788 1209 1 1 0.502 0.349 0.412 644 2 2 0.318 0.158 0.211 171 3 3 0.400 0.048 0.085 84 4 4 0.000 0.000 0.000 1 5 accuracy 0.640 0.640 0.640 0 6 macro avg 0.384 0.292 0.299 2109 7 weighted avg 0.596 0.640 0.598 2109</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="A1_Report_Final_Draft_html_files/figure-html/fig-cm-normalised-5.png" class="img-fluid figure-img" width="432"></p>
<figcaption>Normalised confusion matrix for the test set (rows sum to 1). Numbers in cells are proportions.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="effect-of-threshold-calibration" class="level3">
<h3 class="anchored" data-anchor-id="effect-of-threshold-calibration">Effect of Threshold Calibration</h3>
<p>Tuned monotone thresholds are intended to improve ordinal agreement over the default <span class="math inline">\(0.5\)</span> cut-offs.</p>
<style type="text/css">
#T_a39b0 th {
  text-align: right;
}
#T_a39b0 td {
  text-align: right;
}
#T_a39b0 caption {
  caption-side: top;
  font-weight: 600;
}
#T_a39b0_row0_col0, #T_a39b0_row1_col0 {
  text-align: left;
  white-space: nowrap;
}
#T_a39b0_row0_col1, #T_a39b0_row0_col2, #T_a39b0_row0_col3, #T_a39b0_row0_col4, #T_a39b0_row1_col1, #T_a39b0_row1_col2, #T_a39b0_row1_col3, #T_a39b0_row1_col4 {
  font-weight: 700;
}
</style>
<table id="T_a39b0" class="table table-sm table-striped">
<caption>
Performance comparison between tuned <span class="math inline">\(\tau\)</span> cutoffs and a flat 0.5 cutoff.
</caption>
<thead>
<tr>
<th id="T_a39b0_level0_col0" class="col_heading level0 col0">
Cutoffs
</th>
<th id="T_a39b0_level0_col1" class="col_heading level0 col1">
Accuracy
</th>
<th id="T_a39b0_level0_col2" class="col_heading level0 col2">
Macro-F1
</th>
<th id="T_a39b0_level0_col3" class="col_heading level0 col3">
MAE
</th>
<th id="T_a39b0_level0_col4" class="col_heading level0 col4">
QWK
</th>
</tr>
</thead>
<tbody>
<tr>
<td id="T_a39b0_row0_col0" class="data row0 col0">
tuned <span class="math inline">\(\tau\)</span>
</td>
<td id="T_a39b0_row0_col1" class="data row0 col1">
0.640
</td>
<td id="T_a39b0_row0_col2" class="data row0 col2">
0.299
</td>
<td id="T_a39b0_row0_col3" class="data row0 col3">
0.438
</td>
<td id="T_a39b0_row0_col4" class="data row0 col4">
0.406
</td>
</tr>
<tr>
<td id="T_a39b0_row1_col0" class="data row1 col0">
0.5 flat
</td>
<td id="T_a39b0_row1_col1" class="data row1 col1">
0.640
</td>
<td id="T_a39b0_row1_col2" class="data row1 col2">
0.299
</td>
<td id="T_a39b0_row1_col3" class="data row1 col3">
0.438
</td>
<td id="T_a39b0_row1_col4" class="data row1 col4">
0.406
</td>
</tr>
</tbody>
</table>
<p>We re-evaluated the test set twice: once using the tuned monotone thresholds <span class="math inline">\(\tau = [0.52, 0.50, 0.50, 0.48]\)</span><br>
and once using flat <span class="math inline">\(0.5\)</span> cut-offs for all CORN logits. The two runs produced identical results:<br>
Accuracy <span class="math inline">\(= 0.648\)</span>, Macro-F1 <span class="math inline">\(= 0.295\)</span>, MAE <span class="math inline">\(= 0.433\)</span>, QWK <span class="math inline">\(= 0.390\)</span>.</p>
<p>This tells us that, on this test window, threshold calibration did not change any predicted labels.<br>
That is consistent with two facts: (i) the tuned <span class="math inline">\(\tau\)</span> are very close to <span class="math inline">\(0.5\)</span>, and (ii) most cumulative probabilities were far from the decision boundaries, so nudging thresholds within <span class="math inline">\(0.48\)</span>-<span class="math inline">\(0.52\)</span> doesn�t flip classes.</p>
<p>This implies the model�s test performance is driven by the sequence model and learned representations, rather than by the post-hoc thresholds. We keep the tuned <span class="math inline">\(\tau\)</span> for completeness and because they can help when class balance shifts, but we do <strong>not</strong> claim a test-set gain from calibration here. If thresholding becomes more influential (e.g., under stronger distribution shift), broader grids, direct QWK optimisation, or area-specific <span class="math inline">\(\tau\)</span> could be explored.</p>
</section>
<section id="error-shape" class="level3">
<h3 class="anchored" data-anchor-id="error-shape">Error Shape</h3>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="A1_Report_Final_Draft_html_files/figure-html/fig-error-shape-7.png" class="img-fluid figure-img" width="480"></p>
<figcaption>Histogram of absolute errors <span class="math inline">\(|y_{\text{true}} - y_{\text{pred}}|\)</span> on the test set. Bars are centred at integer steps. Most errors are within one category, consistent with MAE <span class="math inline">\(\approx 0.43\)</span>.</figcaption>
</figure>
</div>
</div>
</div>
<p>The figure above shows the distribution of absolute errors <span class="math inline">\(|y_{\text{true}} - y_{\text{pred}}|\)</span> across FAH levels.<br>
The model achieves an exact match on about 65% of test days (error <span class="math inline">\(= 0\)</span>), and a further <span class="math inline">\(\sim 28\)</span>-<span class="math inline">\(29\%\)</span> are off by one category. Only <span class="math inline">\(\sim 6\%\)</span> are off by two and <span class="math inline">\(&lt;1\%\)</span> by three; no four-step errors occur.</p>
<p>This aligns with the summary statistics (MAE <span class="math inline">\(\approx 0.43\)</span>, median absolute error <span class="math inline">\(\approx 0\)</span>):<br>
in an ordinal setting, most misclassifications are near misses. Operationally, this means the model is usually within one hazard step of the issued level, even when it is wrong.</p>
</section>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<p>The held-out results paint a clear picture. Hazards in this period are highly persistent and skewed toward the lower levels, and the naive persistence rule (“predict today as yesterday within area”) performs very strongly on all summary metrics. Our tuned LSTM-CORN improves markedly over the two majority baselines, but it does not beat persistence on this particular test window.</p>
<section id="metrics-and-diagnostics" class="level3">
<h3 class="anchored" data-anchor-id="metrics-and-diagnostics">Metrics and diagnostics</h3>
<p>Accuracy and MAE are reasonable for the neural model, but the QWK and macro-F1 show performance drops higher up the scale. This is consistent with the near-diagonal confusion matrix that has a downward bias (Level 1 is often pushed to 0; Levels 2-3 are frequently mapped to 1) while extreme over-calls are rare. The error histogram shows most misses are within one category (consistent with MAE <span class="math inline">\(\approx 0.43\)</span>): useful for avoiding false alarms, but conservative relative to true highs. Finally, threshold calibration had almost no effect (tuned <span class="math inline">\(\tau \approx [0.52, 0.50, 0.50, 0.48]\)</span> and gave identical results to 0.5), which implies the limiting factor is representation/sequence learning, not the label cut-offs.</p>
</section>
<section id="factors-underpinning-persistence-performance" class="level3">
<h3 class="anchored" data-anchor-id="factors-underpinning-persistence-performance">Factors underpinning Persistence performance</h3>
<p>Two data realities favour the <span class="math inline">\(y[t-1]\)</span> rule:<br>
(i) strong day-to-day autocorrelation in FAH;<br>
(ii) imbalance and shift: the test window contains no “High” days and is dominated by Levels 0-1. In that regime, copying yesterday is genuinely hard to beat. The LSTM-CORN learns the ordinal structure and avoids wild swings, but with few upper-level examples and a short 14-day context, it struggles to escalate to 2-3 when the series does move. Persistence is not affected by the data imbalance like the LSTM, and is in fact aided by it (response is more uniform for test set).</p>
</section>
<section id="operational-interpretation" class="level3">
<h3 class="anchored" data-anchor-id="operational-interpretation">Operational interpretation</h3>
<p>If the near-term goal is to minimise false alarms, the current calibration is acceptable: errors are mostly one-step and downward. If instead the priority is to catch emerging higher hazards, you would tolerate more false positives and lower the effective thresholds for the top levels (a cost-sensitive calibration). Either way, persistence remains a strong benchmark, and the neural-persistence disagreements are useful review flags.</p>
</section>
<section id="limitations" class="level3">
<h3 class="anchored" data-anchor-id="limitations">Limitations</h3>
<p>Conclusions are conditioned on this split: the test window lacks class 4 entirely and has very few class 3 days, so per-class scores at the top end are unstable. The dataset is modest for sequence models, labels may contain operational noise, and we restricted the model to observed histories (no external forecasts), which caps lead-time sensitivity. We mitigated leakage with forward-chaining folds and an embargo, but results will vary with split point and winter severity.</p>
</section>
<section id="possible-future-improvements" class="level3">
<h3 class="anchored" data-anchor-id="possible-future-improvements">Possible future improvements</h3>
<p>Short-to-medium steps that fit the current pipeline:</p>
<ul>
<li><strong>Longer and/or multi-scale context</strong> (e.g., 28-45 days plus recent 7-day summary features) to help detect trend changes.<br>
</li>
<li><strong>Area- or season-specific calibration</strong> of <span class="math inline">\(\tau\)</span>, or a simple <strong>cost-sensitive threshold</strong> that weights upward errors more heavily.<br>
</li>
<li><strong>Richer dynamics</strong>: include forecasted weather (when available) and simple change features (day-to-day deltas, 7-day slopes).<br>
</li>
<li><strong>Ordinal-aware loss variants</strong> (e.g., ordinal focal/Tversky) to emphasise rare upward moves without exploding false alarms.<br>
</li>
<li><strong>Modeling with persistence</strong> rather than against it: feed <span class="math inline">\(y[t-1]\)</span> explicitly (we already include it) and/or ensemble the neural model with the persistence rule; use the ensemble to trigger escalation only when both agree.</li>
</ul>
<p>For this winter slice, FAH rewards yesterday-equals-today. The LSTM-CORN gives mostly one-step, conservative predictions and clearly outperforms majority rules, but not persistence. With more imbalance-aware training, longer context, and cost-sensitive calibration or ensembling, it should provide earlier and more reliable hazard signals while retaining low false-alarm rates.</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>This work developed a reproducible pipeline for ordinal avalanche forecasting, combining structured data preparation, time-aware validation, and an LSTM-CORN model adjusted for class imbalance and monotone decision thresholds. On the held-out test window, the neural model outperforms both majority baselines but does not surpass persistence. This is expected given the strong day-to-day autocorrelation and the concentration of FAH at lower levels during this period.</p>
<p>The diagnostics are consistent with this outcome. The confusion matrix is near-diagonal with a slight downward bias, MAE (<span class="math inline">\(\approx 0.43\)</span>) indicates that most errors fall within one category, and threshold calibration has negligible effect. This suggests that the main limitations lie in the data regime and sequence representation rather than in the choice of decision cut-offs.</p>
<p>From an operational perspective, the model is conservative and unlikely to produce extreme over-warnings. Its greatest value is in cases where it diverges from persistence, indicating potential changes in hazard. Sensitivity to rising risk could be improved through longer or multi-scale look-back periods, cost-sensitive or area- and season-specific calibration, the inclusion of forecasted weather and change features, and the use of ordinal focal or Tversky losses, or ensembling with persistence.</p>
<p>Additional “High” days and further winters will help stabilise estimates at the upper levels. Overall, the method is interpretable and extensible. With targeted refinements, it has the potential to provide earlier and more reliable indicators of increasing avalanche hazard while maintaining a low false alarm rate.</p>
<div style="page-break-after: always;"></div>
</section>
<section id="statement-on-the-use-of-ai-llms" class="level2">
<h2 class="anchored" data-anchor-id="statement-on-the-use-of-ai-llms">Statement on the use of AI (LLMs)</h2>
<p>ChatGPT (GPT-5 Thinking, GPT-4) was used as a supporting tool for planning, explanation, code syntax and polishing, and presentation. All final decisions, algorithmic design, checks, and writing are our own.</p>
<section id="ai-implementation-and-utilisation" class="level3">
<h3 class="anchored" data-anchor-id="ai-implementation-and-utilisation">AI Implementation and utilisation</h3>
<section id="ideas-planning-high-level-non-code" class="level4">
<h4 class="anchored" data-anchor-id="ideas-planning-high-level-non-code">1) Ideas &amp; planning (high-level, non-code)</h4>
<p>At the start, we shared the assignment brief and asked for a sensible three-way split to manage scope and timelines (data preparation, modelling, and report integration). The initial split helped us coordinate responsibilities, and we adapted it to our context. See the following link: (https://chatgpt.com/share/68d91860-f4a4-8006-ae9c-06e71721af0a).</p>
</section>
<section id="code" class="level4">
<h4 class="anchored" data-anchor-id="code">2) Code</h4>
<ul>
<li><strong>Data prep (R):</strong> LLMs were used to support the design of the data cleaning pipeline, including handling missing values, detecting outliers, and ensuring correct variable types. They also assisted with R syntax and efficient use of packages such as dplyr and tidymodels. Prompts were kept concise and outputs validated step by step to ensure reliability.<br>
</li>
<li><strong>Modelling (PyTorch):</strong> LLMs were used to brainstorm ideas around the architecture of the model and assess the feasibility and efficacy of different approaches. It was also used to get Python syntax and data structures correct, as we are not fluent in that language or the Pytorch library. Steps were followed to ensure best practice in the use of LLMs, such as conserving tokens were ever possible, through concise and specific prompts, and requested limited output unless otherwise prompted. Would the end of the context length was reached, we generated summaries of our chats and put them at the start of the following chat.</li>
</ul>
</section>
<section id="code-polishing-integration" class="level4">
<h4 class="anchored" data-anchor-id="code-polishing-integration">3) Code polishing &amp; integration</h4>
<p>We used AI to make code presentable and navigable inside the report so a reader can follow the narrative and the code together:</p>
<ul>
<li>Refactored and streamlined/condensed code blocks (docstrings, clearer names, comments) without changing logic.<br>
</li>
<li>Added Quarto-friendly chunks (labels, captions, seeds) so outputs render reproducibly in PDF, this was especially utilised for Python chunks.<br>
</li>
<li>Wrote small utilities for CORN threshold tuning, evaluation, and plotting (confusion-matrix heatmap, metric tables), and debugged minor issues.<br>
</li>
<li>Double-checked that the time split and folds prevented leakage, and that train/test separation was respected in every data path.</li>
</ul>
<p>Any AI-suggested code was run directly by us, and retained only if it was correct, readable, and consistent with our pipeline.</p>
</section>
<section id="writing-supplementary-assistance---we-retained-authorial-control" class="level4">
<h4 class="anchored" data-anchor-id="writing-supplementary-assistance---we-retained-authorial-control">4) Writing (supplementary assistance - we retained authorial control)</h4>
<p>We used AI as an editor and explainer, not as an author. It helped with coverage checks, clarity, and presentation. We kept control of the structure, final wording, and all technical claims.</p>
<ul>
<li><strong>Coverage audit of Methods vs code:</strong> We asked AI to cross-check that everything happening in the code is actually described in the text (e.g., sequence construction, forward-chaining folds with an embargo, CORN targets and loss, threshold tuning, baselines). It flagged a few gaps and we filled them. Anything inaccurate was discarded.<br>
</li>
<li><strong>Plain-language tightening:</strong> It suggested alternative phrasings for the LSTM/CORN/QWK explanations and helped trim repetition so sections read cleanly without losing technical meaning.<br>
</li>
<li><strong>Flow and structure:</strong> It helped reorder sentences and add short signposts so paragraphs read as a narrative rather than a list of steps. However, overall narrative flow in the report is above the current abilities of AI (or at least for it to be done well and efficiently), so this was done independently.</li>
<li><strong>Captions and presentation:</strong> It drafted first-pass figure/table captions, and we then aligned labels, units, and legends (e.g., rows=true/cols=pred in the confusion matrix, and helped provide metric definitions for us to include under the comparison table).<br>
</li>
<li><strong>Consistency sweep:</strong> We used it to spot inconsistencies in symbols and names (e.g., <code>FAH_ord</code>, <span class="math inline">\(K\)</span>, <span class="math inline">\(\tau\)</span>), units (<span class="math inline">\(^\circ C\)</span>, cm, m/s), and split terminology (“train/test”, “validation fold”), and then standardised them across the report.<br>
</li>
<li><strong>Word-count management:</strong> It helped us condense our abstract, introduction, and conclusion into more concise versions. We only kept edits that preserved our meaning and emphasis.<br>
</li>
<li><strong>Micro-explanations for readers:</strong> Where code terms might block understanding (e.g., “oversampling”, “class-balanced loss”), it helped draft one-line, non-jargony explanations that we then rewrote in our own words and integrated within our written report.</li>
</ul>
<p>As a way of keeping authorship and accuracy, we wrote the first drafts ourselves. AI suggestions were used as options, not final text. We rewrote text in our voice, verified technical statements against the code and outputs, and removed anything we did not understand. All numbers, metrics, thresholds, and plots were produced and checked by us.</p>
</section>
</section>
<section id="verification-and-academic-integrity" class="level3">
<h3 class="anchored" data-anchor-id="verification-and-academic-integrity">Verification and academic integrity</h3>
<p>We executed every included code cell and verified shapes, date boundaries, splits, and metrics. We cross-checked explanations against the source code and cited literature. Where AI proposed code or text we didn�t fully understand, we reworked it or removed it. All preprocessing parameters were fit by us on the training set and applied to test via a baked pipeline; seeds and caches were used for reproducibility.</p>
</section>
<section id="representative-prompts" class="level3">
<h3 class="anchored" data-anchor-id="representative-prompts">Representative prompts</h3>
<p>These examples reflect how we used AI (from our initial scoping and idea generation, through iterative prompt refinement, to final verification checks):</p>
<ol type="1">
<li><strong>Planning:</strong> “Given this brief, propose a practical 3-way task split and a checklist of outputs/figures we�ll need. Keep it realistic for a short timeline.”<br>
</li>
<li><strong>Method design:</strong> “In 3 to 4 sentences, justify forward-chaining validation with an embargo for next-day avalanche hazard. Operationally, not mathematically.”<br>
</li>
<li><strong>Learning the ordinal head (CORN):</strong> “I�m reading the Shi, Cao, and Raschka paper and not fully grasping it. Why use <span class="math inline">\(K - 1\)</span> logits for <span class="math inline">\(P(y &gt; k)\)</span>? How are targets built directly from labels, and how do monotone thresholds turn those probabilities into one class? Please explain in plain English with a tiny <span class="math inline">\(K = 5\)</span> example and common pitfalls so I can understand this theory better.”</li>
<li><strong>Imbalance rationale:</strong> “In a couple of sentences, explain why we oversample in batches and use class-balanced weights (<span class="math inline">\(\beta = 0.999\)</span>) for CORN. Emphasise rare exceedances without inventing data.”<br>
</li>
<li><strong>Results narrative:</strong> “Turn this metrics table (Accuracy, Macro-F1, MAE, QWK) into a brief, neutral comparison vs baselines. Additionally, explain what each metric means in one line so that I can try include a brief definitions when I introduce them”</li>
<li><strong>Figure polish (Quarto/PDF):</strong> “Give a captioned confusion-matrix heatmap (rows=true, cols=pred) with a readable palette and percent labels. Make it knitr/Quarto-ready.”<br>
</li>
<li><strong>Quarto snippets:</strong> “Produce labelled, captioned chunks for a confusion-matrix figure and a formatted metrics table suitable for PDF export.”<br>
</li>
<li><strong>Abstract tightening:</strong> “Cut this abstract to around 150 words. Keep aims (LSTM+CORN), time-aware validation, key metrics, and one-line takeaway.”</li>
</ol>
<p>In each case, we reviewed/edited the draft and ran the code to confirm it worked with our data.</p>
</section>
<section id="limits-of-the-ais-role" class="level3">
<h3 class="anchored" data-anchor-id="limits-of-the-ais-role">Limits of the AI�s role</h3>
<ul>
<li><strong>No autonomous analysis:</strong> AI did not choose the final methodology, set hyperparameters, or produce final results. Those came from our group�s design, runs, and checks.<br>
</li>
<li><strong>No blind copying:</strong> We avoided pasting large blocks of AI generated text or code. Anything kept was edited and verified by us.<br>
</li>
<li><strong>Potential inaccuracies:</strong> LLMs can be wrong or overconfident. We treated explanations as suggestions, then validated against code and papers.<br>
</li>
<li><strong>No access to private data or execution:</strong> AI did not run our experiments or access hidden datasets. We executed everything locally and controlled random seeds/caches.<br>
</li>
<li><strong>Authorship and accountability:</strong> All interpretation, synthesis, and conclusions are ours. The AI�s role was assistive, not determinative.</li>
</ul>
</section>
</section>
<section id="benefits" class="level2">
<h2 class="anchored" data-anchor-id="benefits">Benefits</h2>
<p>Using an LLM mainly helped with structure, clarity, and polish while we kept control of the ideas, code, and results.</p>
<ul>
<li><strong>Editorial shaping:</strong> It can take a rough draft and provide insights into how to make it more concise and appropriate for a scientific report, by suggesting tightening sentences. This allows us to still keep our tone and intent intact.<br>
</li>
<li><strong>Clarity through compression:</strong> It reduces repetition and surfaces the main argument, which helped us get to the core of what we were trying to say (especially in terms of structuring a Methods Section and when trying to integrate a short literature review inside the Introduction).<br>
</li>
<li><strong>Decomposing chaotic sections:</strong> When a section felt messy, offered points on how to reorganised it into digestible pieces (clear paragraphs, headings, short lists) so readers can follow the logic.<br>
</li>
<li><strong>Audience-fit translation:</strong> It can help turn code-heavy or jargony passages into plain-English explanations that are self-contained, so the report stands on its own without the reader opening the code.<br>
</li>
<li><strong>Code ideation &amp; efficiency:</strong> Once we were clear on intent, it proposed cleaner patterns (small utilities, vectorised operations, reusable plotting functions). We only kept changes that we verified improved readability or runtime without altering results.<br>
</li>
<li><strong>Formatting and presentation:</strong> It sped up figure/table styling for PDF (captions, labels, palettes, legends) and Quarto chunk hygiene (seeds, paths, cache). This helps save us time we could spend on analysis.<br>
</li>
<li><strong>Consistency checks:</strong> It was useful for quick passes on naming, units, date boundaries, and split logic, reducing accidental inconsistencies across sections.<br>
</li>
<li><strong>Focused learning support:</strong> For more complex sections (e.g., CORN thresholds, QWK) it provided explanations and examples for us to better understand the theory.<br>
</li>
<li><strong>Rapid Idea Generation:</strong> It generated checklists, micro-templates, and alternative phrasings on demand, which helped us move faster without skipping the verification steps.</li>
<li><strong>Checkpoints:</strong> It was useful for quick checks on validation design (forward-chaining + embargo), metric definitions, and common pitfalls. This saved us time while we kept control of decisions.</li>
</ul>
<p>Overall, the LLM worked like a sharp editor and sounding board: it helped us restructure, clarify, and polish, while we did the design, execution, and final judgement calls.</p>
<div style="page-break-after: always;"></div>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><p>Statham, G., Haegeli, P., Greene, E., Birkeland, K., Israelson, C., Tremper, B. and Kelly, J. (2018) ‘A conceptual model of avalanche hazard’, <em>Natural Hazards</em>, 90(2), pp. 663-691. <a href="https://doi.org/10.1007/s11069-017-3070-5" class="uri">https://doi.org/10.1007/s11069-017-3070-5</a>.</p></li>
<li><p>OpenAI (2025) <em>ChatGPT-5 Thinking (Sep 28 version) [Large language model software]</em>. Available at: <a href="https://chatgpt.com/" class="uri">https://chatgpt.com/</a> (Accessed: 28 September 2025).</p></li>
<li><p>OpenAI (2024) <em>ChatGPT-4 (Sep 28 version) [Large language model software]</em>. Available at: <a href="https://chat.openai.com/" class="uri">https://chat.openai.com/</a> (Accessed: 28 September 2025).</p></li>
<li><p>Cui, Y., Jia, M., Lin, T.-Y. and Song, Y. (2019) ‘Class-Balanced Loss Based on Effective Number of Samples’, in <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pp. 9268-9277. <a href="https://doi.org/10.1109/CVPR.2019.00949" class="uri">https://doi.org/10.1109/CVPR.2019.00949</a>.</p></li>
<li><p>Shi, X., Cao, W. and Raschka, S. (2021) ‘Deep Neural Networks for Rank-Consistent Ordinal Regression Based on Conditional Probabilities’, <em>arXiv preprint</em> arXiv:2111.08851. Available at: <a href="https://arxiv.org/abs/2111.08851" class="uri">https://arxiv.org/abs/2111.08851</a>.</p></li>
<li><p>Lim, B. and Zohren, S. (2021) ‘Time-series forecasting with deep learning: a survey’, <em>Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</em>, 379(2194), 20200209. <a href="https://doi.org/10.1098/rsta.2020.0209" class="uri">https://doi.org/10.1098/rsta.2020.0209</a>.</p></li>
</ul>
<div style="page-break-after: always;"></div>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<section id="data-figures" class="level3">
<h3 class="anchored" data-anchor-id="data-figures">Data Figures</h3>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="A1_Report_Final_Draft_html_files/figure-html/unnamed-chunk-41-9.png" class="img-fluid figure-img" width="576"></p>
<figcaption>Proportion of FAH levels in the train and test splits (row-level)</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="A1_Report_Final_Draft_html_files/figure-html/unnamed-chunk-42-1.png" class="img-fluid figure-img" width="480"></p>
<figcaption>Percentage of missing values by variable (top 25).</figcaption>
</figure>
</div>
</div>
</div>
<p>This uniqueness summary indicates that after consolidation, <span class="math inline">\(99.9\%\)</span> of (<code>Date</code>, <code>OSgrid</code>, <code>Area</code>) keys were unique.<br>
We found <span class="math inline">\(12\)</span> keys with duplicates (<span class="math inline">\(8\)</span> keys with 2 rows; <span class="math inline">\(4\)</span> with <span class="math inline">\(\geq 3\)</span>).<br>
Conflict cases were retained and flagged; duplicates that differed only by missingness were collapsed (4 rows collapsed).</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="A1_Report_Final_Draft_html_files/figure-html/unnamed-chunk-48-1.png" class="img-fluid figure-img" width="576"></p>
<figcaption>Observed vs imputed distributions.</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="A1_Report_Final_Draft_html_files/figure-html/unnamed-chunk-48-2.png" class="img-fluid figure-img" width="576"></p>
<figcaption>Observed vs imputed distributions.</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="A1_Report_Final_Draft_html_files/figure-html/unnamed-chunk-48-3.png" class="img-fluid figure-img" width="576"></p>
<figcaption>Observed vs imputed distributions.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="model-results-figures" class="level3">
<h3 class="anchored" data-anchor-id="model-results-figures">Model / Results Figures</h3>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="A1_Report_Final_Draft_html_files/figure-html/unnamed-chunk-49-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption>Per-class precision, recall, and F1 on the test set.</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="A1_Report_Final_Draft_html_files/figure-html/unnamed-chunk-50-3.png" class="img-fluid figure-img" width="864"></p>
<figcaption>Comparison of the neural model to baselines on QWK (higher is better) and MAE (lower is better).</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="A1_Report_Final_Draft_html_files/figure-html/unnamed-chunk-51-5.png" class="img-fluid figure-img" width="480"></p>
<figcaption>Tuned CORN decision thresholds (<span class="math inline">\(\tau\)</span>) used to convert probabilities into ordinal labels.</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="A1_Report_Final_Draft_html_files/figure-html/unnamed-chunk-52-7.png" class="img-fluid figure-img" width="672"></p>
<figcaption>Proportion of FAH levels at the window level (what the LSTM actually trained on) in train vs test.</figcaption>
</figure>
</div>
</div>
</div>



</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>