[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "multiplication.html",
    "href": "multiplication.html",
    "title": "Multiplying numbers in R",
    "section": "",
    "text": "To multiply numbers in R use *\n\n2 * 3\n\n[1] 6"
  },
  {
    "objectID": "data_prep_eda.html",
    "href": "data_prep_eda.html",
    "title": "Data Preparation and EDA",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.7     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.0     ✔ yardstick    1.3.2\n✔ recipes      1.1.1     \n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\n\n\nInvestigate missing data\n\n# quick checks\ncolnames(aval)\n\n [1] \"Date\"              \"Area\"              \"OSgrid\"           \n [4] \"longitude\"         \"latitude\"          \"Alt\"              \n [7] \"Aspect\"            \"Incline\"           \"Location\"         \n[10] \"Obs\"               \"FAH\"               \"OAH\"              \n[13] \"Air.Temp\"          \"Wind.Dir\"          \"Wind.Speed\"       \n[16] \"Cloud\"             \"Precip.Code\"       \"Drift\"            \n[19] \"Total.Snow.Depth\"  \"Foot.Pen\"          \"Ski.Pen\"          \n[22] \"Rain.at.900\"       \"Summit.Air.Temp\"   \"Summit.Wind.Dir\"  \n[25] \"Summit.Wind.Speed\" \"Max.Temp.Grad\"     \"Max.Hardness.Grad\"\n[28] \"No.Settle\"         \"Snow.Index\"        \"Insolation\"       \n[31] \"Crystals\"          \"Wetness\"           \"AV.Cat\"           \n[34] \"Snow.Temp\"        \n\ncolSums(is.na(aval)) # number of missing values in each column\n\n             Date              Area            OSgrid         longitude \n                0                 0                 0                 0 \n         latitude               Alt            Aspect           Incline \n                0                 6               355                36 \n         Location               Obs               FAH               OAH \n                0                 0                 0               369 \n         Air.Temp          Wind.Dir        Wind.Speed             Cloud \n               34               158                53                29 \n      Precip.Code             Drift  Total.Snow.Depth          Foot.Pen \n                0                 0               163                42 \n          Ski.Pen       Rain.at.900   Summit.Air.Temp   Summit.Wind.Dir \n             2404                 0               754              1318 \nSummit.Wind.Speed     Max.Temp.Grad Max.Hardness.Grad         No.Settle \n              909               710               629               289 \n       Snow.Index        Insolation          Crystals           Wetness \n              745               507               988               576 \n           AV.Cat         Snow.Temp \n             2494               410 \n\nstr(aval) # data type of each column\n\n'data.frame':   10671 obs. of  34 variables:\n $ Date             : chr  \"2009-12-17 12:30:00\" \"2009-12-18 13:15:00\" \"2009-12-19 13:15:00\" \"2009-12-20 12:50:00\" ...\n $ Area             : chr  \"Creag Meagaidh\" \"Creag Meagaidh\" \"Creag Meagaidh\" \"Creag Meagaidh\" ...\n $ OSgrid           : chr  \"NN460901\" \"NN442895\" \"NN448897\" \"NN463900\" ...\n $ longitude        : num  -4.54 -4.56 -4.55 -4.53 -4.55 ...\n $ latitude         : num  57 57 57 57 57 ...\n $ Alt              : int  800 890 NA 890 900 730 700 800 600 600 ...\n $ Aspect           : int  160 100 NA 130 100 155 150 130 190 120 ...\n $ Incline          : int  28 32 NA 39 33 31 35 25 20 28 ...\n $ Location         : chr  \"Cairn Liath\" \"Lifa Gully, Coire Chriochairein\" \"Wall gully,Coire Chreiochairein\" \"Balloon Gully\" ...\n $ Obs              : chr  \"WS\" \"TR\" \"TR\" \"TR\" ...\n $ FAH              : chr  \"Moderate\" \"Considerable -\" \"Considerable +\" \"Considerable +\" ...\n $ OAH              : chr  \"Moderate\" \"Considerable +\" \"High\" \"Considerable +\" ...\n $ Air.Temp         : num  -3.2 -2.5 -5 -2 -2.6 -7.8 -0.5 -3 -1 -2 ...\n $ Wind.Dir         : num  45 340 NA 270 NA NA NA NA 45 45 ...\n $ Wind.Speed       : num  10 30 35 25 5 0 3 NA 5 2 ...\n $ Cloud            : int  90 100 100 60 90 0 100 10 2 20 ...\n $ Precip.Code      : chr  \"2 - Trace\" \"4 - Light Showers\" \"8 - Snow\" \"6 - Snow Showers\" ...\n $ Drift            : int  1 1 1 1 1 0 1 0 1 0 ...\n $ Total.Snow.Depth : int  45 40 65 75 80 64 60 52 41 42 ...\n $ Foot.Pen         : num  0 10 33 50 70 42 50 50 40 30 ...\n $ Ski.Pen          : int  NA NA NA NA 25 30 20 NA NA NA ...\n $ Rain.at.900      : int  0 0 0 0 0 0 0 0 0 0 ...\n $ Summit.Air.Temp  : num  NA NA NA NA NA NA NA NA NA NA ...\n $ Summit.Wind.Dir  : int  NA NA NA NA NA NA NA NA NA NA ...\n $ Summit.Wind.Speed: int  NA NA NA NA NA NA NA NA NA NA ...\n $ Max.Temp.Grad    : num  20 8 18 5 10 43 4 18 34 17 ...\n $ Max.Hardness.Grad: int  4 2 2 2 2 2 2 3 3 3 ...\n $ No.Settle        : int  NA NA NA NA NA NA NA NA NA NA ...\n $ Snow.Index       : int  NA NA NA NA NA NA NA NA NA NA ...\n $ Insolation       : int  NA NA NA NA NA NA NA NA NA NA ...\n $ Crystals         : int  NA NA NA NA NA NA NA NA NA NA ...\n $ Wetness          : int  NA NA NA NA NA NA NA NA NA NA ...\n $ AV.Cat           : int  NA NA NA NA NA NA NA NA NA NA ...\n $ Snow.Temp        : num  NA NA NA NA NA NA NA NA NA NA ...\n\n# remove OAH: observed avalanche hazard\naval &lt;- aval %&gt;% select(-OAH)\n\n\n# clean the data by casting variables as correct types\n# STEP 1 — Fix types & engineer helper features (with OAH removed)\n\naval &lt;- aval %&gt;%\n  mutate(\n    # --- time features ---\n    DateTime = ymd_hms(Date, quiet = TRUE),\n    # strip out year, month and day:\n    Date     = as.Date(DateTime),\n    year     = year(Date),\n    month    = month(Date),\n    doy      = yday(Date),\n    # create a new variable: season\n    season   = factor(case_when(\n      month %in% c(12,1,2) ~ \"DJF\",\n      month %in% c(3,4,5)  ~ \"MAM\",\n      month %in% c(6,7,8)  ~ \"JJA\",\n      TRUE                 ~ \"SON\"\n    ), levels = c(\"DJF\",\"MAM\",\"JJA\",\"SON\")),\n\n    # --- categorical / IDs ---\n    Area     = factor(Area),\n    OSgrid   = as.character(OSgrid),\n    Location = as.character(Location),\n    Obs      = factor(Obs),\n\n    # --- hazard (target) as ordered factor ---\n    FAH_ord  = factor(\n      FAH,\n      # specify the following order:\n      levels  = c(\"Low\",\"Moderate\",\"Considerable -\",\"Considerable\",\"Considerable +\",\"High\"),\n      ordered = TRUE\n    ),\n\n    # --- circular encodings for angles ---\n    # since 0 degrees is equivalent to 360, we change these variables.\n    # ex. 350 is close to 0 directionally, but numerically far\n    # map angles onto unit circle\n    Wind.Dir_sin        = sin(pi * Wind.Dir/180),\n    Wind.Dir_cos        = cos(pi * Wind.Dir/180),\n    Summit.Wind.Dir_sin = sin(pi * Summit.Wind.Dir/180),\n    Summit.Wind.Dir_cos = cos(pi * Summit.Wind.Dir/180),\n\n    # aspect (if degrees)\n    Aspect_sin = sin(pi * Aspect/180),\n    Aspect_cos = cos(pi * Aspect/180)\n  )\n\n# remove the original variables:\naval &lt;- aval %&gt;%\n  select(-Wind.Dir, -Summit.Wind.Dir, -Aspect)   # drop originals\n\n\n# number of unique and missing values for each variable:\nn_total &lt;- nrow(aval)\n\nvar_summary &lt;- aval %&gt;%\n  summarise(across(\n    everything(),\n    list(\n      unique_vals  = ~n_distinct(.),\n      missing_vals = ~sum(is.na(.))\n    ),\n    .names = \"{.col}__{.fn}\"      # &lt;-- double underscore here\n  )) %&gt;%\n  pivot_longer(\n    everything(),\n    names_to   = c(\"variable\", \".value\"),\n    names_sep  = \"__\"             # &lt;-- and the same separator here\n  ) %&gt;%\n  mutate(pct_missing = round(100 * missing_vals / n_total, 2)) %&gt;%\n  arrange(desc(pct_missing), variable)\n\nvar_summary\n\n# A tibble: 42 × 4\n   variable            unique_vals missing_vals pct_missing\n   &lt;chr&gt;                     &lt;int&gt;        &lt;int&gt;       &lt;dbl&gt;\n 1 AV.Cat                       17         2494       23.4 \n 2 Ski.Pen                      29         2404       22.5 \n 3 Summit.Wind.Dir_cos         322         1318       12.4 \n 4 Summit.Wind.Dir_sin         323         1318       12.4 \n 5 Crystals                     10          988        9.26\n 6 Summit.Wind.Speed           144          909        8.52\n 7 Summit.Air.Temp             222          754        7.07\n 8 Snow.Index                   57          745        6.98\n 9 Max.Temp.Grad               110          710        6.65\n10 Max.Hardness.Grad             7          629        5.89\n# ℹ 32 more rows\n\n\n\n# is long and lat constant within OSgrid?\naval %&gt;%\n  group_by(OSgrid) %&gt;%\n  summarise(n_coords = n_distinct(paste(longitude, latitude)), .groups = \"drop\") %&gt;%\n  filter(n_coords &gt; 1)\n\n# A tibble: 0 × 2\n# ℹ 2 variables: OSgrid &lt;chr&gt;, n_coords &lt;int&gt;\n\n# yes, thus long and lat is the coordinates of different sites, OSgrid\n\n# is Alt the same within each OSgrid?\naval %&gt;%\n  group_by(OSgrid) %&gt;%\n  summarise(n_alt = n_distinct(Alt), .groups = \"drop\") %&gt;%\n  filter(n_alt &gt; 1)\n\n# A tibble: 1,271 × 2\n   OSgrid   n_alt\n   &lt;chr&gt;    &lt;int&gt;\n 1 NG773424     3\n 2 NG773426     2\n 3 NG774425     5\n 4 NG774426     2\n 5 NG777424     2\n 6 NG777425     4\n 7 NG778413     2\n 8 NG778415     2\n 9 NG779424     2\n10 NG780424     2\n# ℹ 1,261 more rows\n\n## no: cannot use Osgrid to impute missing Alt\n\n\n# Per-variable % missing\nmiss_summary &lt;- aval %&gt;%\n  summarise(across(\n    everything(),\n    ~mean(is.na(.)) * 100\n  )) %&gt;%\n  pivot_longer(everything(), names_to = \"variable\", values_to = \"pct_missing\") %&gt;%\n  arrange(desc(pct_missing))\n\nmiss_summary\n\n# A tibble: 42 × 2\n   variable            pct_missing\n   &lt;chr&gt;                     &lt;dbl&gt;\n 1 AV.Cat                    23.4 \n 2 Ski.Pen                   22.5 \n 3 Summit.Wind.Dir_sin       12.4 \n 4 Summit.Wind.Dir_cos       12.4 \n 5 Crystals                   9.26\n 6 Summit.Wind.Speed          8.52\n 7 Summit.Air.Temp            7.07\n 8 Snow.Index                 6.98\n 9 Max.Temp.Grad              6.65\n10 Max.Hardness.Grad          5.89\n# ℹ 32 more rows\n\n# Visual overview\nnaniar::gg_miss_var(aval)\n\n\n\n\n\n\n\nnaniar::vis_miss(aval)\n\n\n\n\n\n\n\n\nFrom the above, only 10 variables have more than 5% of their values missing. Careful attention is paid to these below. The remaining variables have \\(&lt;5\\%\\) missing values and will simply be imputed with a K-Nearest Neighbor approach.\nOf the variables missing more than 5%, we first need to determine if the missingness carries meaning. The list of variables is thus split in two, one where missingness does carry meaning and need to be accounted for and one where it does not.\nThe variables that do need to be accounted for and the method to account for it are:\nThose that do not need to be accounted for are:\nThese variables will also be imputed with KNN.\n\nunique(aval$AV.Cat)\n\n [1]    NA     3    -2     2     1     4  8800    -1     0  1021  4400 -9999\n[13]    99    88    44  5031   121\n\nunique(aval$Ski.Pen)\n\n [1] NA 25 30 20 15 10  7  9 12 23  5  1 40  6  8 50 -1 55  0  4 17 39  2  3 16\n[26] 22 18 35 45\n\n\ntodo - check for duplicates after imputing missing values. (noticed there are less unique dates than there are # obs)"
  }
]