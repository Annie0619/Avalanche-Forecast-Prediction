"0","# STEP 2 — NN-ready preprocessing with recipes --------------------------------"
"0",""
"0","# 1) Choose columns to DROP (IDs, raw angles, dates, free text) ---------------"
"0","drop_cols <- intersect("
"0","  c("
"0","    ""FAH"",                # raw target (we'll use FAH_ord)"
"0","    ""Date"", ""DateTime"",   # time stamps (we keep year/month/doy/season)"
"0","    ""Wind.Dir"", ""Summit.Wind.Dir"", ""Aspect"",   # raw angles (keep sin/cos)"
"0","    ""OSgrid"",             # grid ID (too high-cardinality for one-hot)"
"0","    ""Location""            # often messy/free-text; drop for NN baseline"
"0","  ),"
"0","  names(train)"
"0",")"
"0",""
"0","# 2) Identify informative-missing flags so we can avoid scaling them ----------"
"0","flag_prefixes <- c("
"0","  ""av_cat_missing"", ""ski_pen_missing"", ""crystals_missing"","
"0","  ""wetness_missing"", ""snow_index_missing"","
"0","  ""summit_wind_dir_missing"", ""summit_wind_speed_missing"", ""summit_air_temp_missing"""
"0",")"
"0","flag_cols <- unique(unlist(lapply(flag_prefixes, function(p) grep(p, names(train), value = TRUE))))"
"0","# You may have named them with `_initial`. If so, they’ll be picked up by grep above."
"0",""
"0","# 3) Build the recipe ---------------------------------------------------------"
"0","rec <- recipe(FAH_ord ~ ., data = train) %>% "
"0","  # drop columns we don't want to feed to the NN"
"0","  step_rm(all_of(drop_cols)) %>%"
"0","  # explicitly confirm Area is a predictor (this line is optional, since it’s already a predictor by default)"
"0","  update_role(Area, new_role = ""predictor"") %>%"
"0","  # collapse *very* rare categories to ""other"""
"0","  step_other(all_nominal_predictors(), threshold = 0.005, other = ""other"") %>% "
"0","  # impute categoricals by mode"
"0","  step_impute_mode(all_nominal_predictors()) %>%"
"0","  # impute numerics by bagged trees"
"0","  step_impute_bag(all_numeric_predictors()) %>%"
"0","  # one-hot encode categoricals"
"0","  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%"
"0","  # drop zero-variance and near-zero-variance columns"
"0","  step_zv(all_predictors()) %>%"
"0","  step_nzv(all_predictors()) %>%"
"0","  # scale/center numerics (excluding the missingness flags)"
"0","  step_normalize(all_numeric_predictors(), -all_of(flag_cols))"
"0",""
"0",""
"0","# 4) Prep on TRAIN only, then bake to splits ---------------------------------"
"0","rec_prep <- prep(rec, training = train, retain = TRUE)"
"0","# this calculates the mean/sd for scaling, finds the mode of categoricals, trains the bagged trees for imputation."
"0",""
"0","x_train <- bake(rec_prep, new_data = train) # apply to train set"
"0","x_val   <- bake(rec_prep, new_data = val) # apply to val set"
"0","x_test  <- bake(rec_prep, new_data = test) # apply to test set"
"0",""
"0","# 5) Quick sanity checks ------------------------------------------------------"
"0","cat(""Shapes:\n"")"
"1","Shapes:
"
"0","cat(""  train:"", dim(x_train)[1], ""rows x"", dim(x_train)[2], ""cols\n"")"
"1","  train:"
"1"," "
"1","7396"
"1"," "
"1","rows x"
"1"," "
"1","65"
"1"," "
"1","cols
"
"0","cat(""  val  :"", dim(x_val)[1],   ""rows x"", dim(x_val)[2],   ""cols\n"")"
"1","  val  :"
"1"," "
"1","1584"
"1"," "
"1","rows x"
"1"," "
"1","65"
"1"," "
"1","cols
"
"0","cat(""  test :"", dim(x_test)[1],  ""rows x"", dim(x_test)[2],  ""cols\n\n"")"
"1","  test :"
"1"," "
"1","1578"
"1"," "
"1","rows x"
"1"," "
"1","65"
"1"," "
"1","cols

"
"0","cat(""Any NA left? "","
"0","    any(vapply(x_train, function(col) any(is.na(col)), logical(1))),"
"0","    any(vapply(x_val,   function(col) any(is.na(col)), logical(1))),"
"0","    any(vapply(x_test,  function(col) any(is.na(col)), logical(1))), ""\n"")"
"1","Any NA left? "
"1"," "
"1","FALSE"
"1"," "
"1","FALSE"
"1"," "
"1","FALSE"
"1"," "
"1","
"
"0","cat(""\nTarget distribution after preprocessing (train):\n"")"
"1","
Target distribution after preprocessing (train):
"
"0","print(table(x_train$FAH_ord))"
"1","
"
"1","           Low "
"1","      Moderate "
"1","Considerable - "
"1","Considerable + "
"1","          High "
"1","
"
"1","          1628 "
"1","          2293 "
"1","          2200 "
"1","           819 "
"1","           456 "
"1","
"
